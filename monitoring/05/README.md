# Домашняя работа к занятию 17 «Инцидент-менеджмент»

## Постмортем на основе реального сбоя системы GitHub в 2018 году

Информация о сбое:

* [краткое описание на русском языке](https://habr.com/ru/post/427301/);
* [развёрнутое описание на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

## Описание инцидента

21 октября 2018 года в 22:52 UTC произошёл инцидент - множество сервисов на GitHub.com были поражены по сетевой части и последующим сбоем базы данных, что привело к несогласованности информации, представленной на веб-сайте GitHub.

## Предшествующие события

21 октября в 22:52 UTC плановые работы по техническому обслуживанию по замене неисправного оптического оборудования 100G привели к потере соединения между сетевым узлом на US West Coast и основным центром обработки данных US West Coast. Соединение между этими точками было восстановлено за 43 секунды, но этот кратковременный сбой вызвал цепочку событий, которые привели к ухудшению качества обслуживания на 24 часа и 11 минут.

## Причина инцидента

Согласно консенсусу Raft, во время разделения сети, Orchestrator, который был активен в US West Coast - основном центре обработки данных, начал процесс отмены выбора мастер-ноды. Центр обработки данных US West Coast и узлы Orchestrator общедоступного облака US East Coast смогли установить кворум и начать обработку отказа кластеров для направления операций записи в центр обработки данных US East Coast. Orchestrator приступил к организации топологии кластера базы данных US West Coast. Когда подключение было восстановлено, приложения немедленно начали направлять трафик записи на новые основные узлы на сайте US West Coast.

Серверы баз данных в центре обработки данных US East Coast содержали короткий период записей, которые не были реплицированы на объект на US West Coast. Поскольку кластеры баз данных в обоих центрах обработки данных теперь содержали операции записи, которых не было в другом центре обработки данных, мы не смогли безопасно перенести основной сервер в центр обработки данных на US East Coast.

## Воздействие

С 21 октября 23:19 UTC была отключена запись новых данных в кластер БД с целью приведения в консистентное состояние кластера БД. Что привело к ухудшению качества обслуживания - многие сервисы перестали принимать новые данные, а могли только отображать зафиксированные до инцидента данные.

## Обнаружение инцидента

21 октября 22:54 UTC внутренние системы мониторинга начали генерировать оповещения, указывающие на многочисленные сбои в наших системах. К 23:02 UTC инженеры нашей группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в неожиданном состоянии.

## Реакция на инцидент

* Группа реагирования в 23:11 UTC привлекла координатора инцидентов.
* 21 октября 23:13 UTC были вызваны дополнительные инженеры из группы разработки баз данных GitHub.
* С 21 октября 23:19 UTC была отключена запись новых данных в кластер БД с целью приведения в консистентное состояние кластера БД.
* 22 октября 00:05 UTC - сообщили пользователям, что мы собираемся выполнить контролируемый переход на другой ресурс внутренней системы хранения данных.

## Восстановление

22 октября 00:05 UTC Инженеры, участвующие в группе реагирования на инциденты, начали разработку плана по устранению несоответствий данных и реализации наших процедур аварийного переключения для MySQL.

План восстановления:

* восстановиться из резервных копий,
* синхронизировать реплики на обоих сайтах,
* вернуться к стабильной топологии обслуживания,
* возобновить обработку заданий в очереди.

## Таймлайн восстановления

* 21 октября 22:52 UTC начало плановых работ по сетевому оборудованию
* 21 октября 22:54 UTC обнаружение инцидента о сбое в кластерах БД
* 21 октября 23:13 UTC начало работ по решению инцидента.
* 21 октября 23:19 UTC была отключена запись новых данных в кластер БД.
* 22 октября 00:05 UTC начало разработки плана по восстановлению.
* 22 октября 00:41 UTC начало процесса резервного восстановления для всех затронутых кластеров MySQL.
* 22 октября 06:51 UTC несколько кластеров завершили восстановление из резервных копий в нашем центре обработки данных на US East Coast и начали репликацию новых данных с US West Coast.
* 22 октября 11:12 UTC все первичные базы данных снова установлены на US West Coast.
* 22 октября 16:24 UTC все реплики были синхронизированы, выполнен переход на исходную топологию, решены проблемы с задержкой и доступностью.
* 22 октября 16:45 UTC начало обработки очередей.
* 22 октября 23:03 UTC восстановление завершено.

## Последующие действия

* Анализ и корректировка работы Orchestrator для исключения подобных инцидентов.
* Переход на новый механизм отчетности о статусе работы служб.
* Переход на топологию ЦОД N+1 active/active/active.
* Внедрение хаос-инжениринга.
* Улучшение качества коммуникаций с пользователями.
